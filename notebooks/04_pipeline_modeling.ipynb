{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5900897-055f-4c43-9575-e2fa39303ae9",
   "metadata": {},
   "source": [
    "#### Import Libraries and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "165cdd46-224e-4602-8b97-d1c309f1e9b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully!\n",
      "Working directory: C:\\Users\\Carlos\\Documents\\Data Science program\\000 my_models\\001_portfolio_house_prices\\house-prices-advanced-regression-techniques\\notebooks\n"
     ]
    }
   ],
   "source": [
    "# Import essential libraries for pipeline modeling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Machine learning libraries\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "import xgboost as xgb\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"viridis\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "print(\"All libraries imported successfully!\")\n",
    "print(f\"Working directory: {Path.cwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4560fcc1-ab1a-4e84-bc5d-0526a5e8ccf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0dd5f265-4e6b-48f0-bd53-163f1169b25a",
   "metadata": {},
   "source": [
    "#### Load Data and Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02230ace-5274-42aa-b4ec-67cca48ecc1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded:\n",
      "Training data shape: (1460, 81)\n",
      "Test data shape: (1459, 80)\n",
      "FeatureEngineer imported from module\n",
      "Preprocessing pipeline loaded successfully!\n",
      "Pipeline steps:\n",
      "  1. feature_engineering: FeatureEngineer\n",
      "  2. preprocessing: ColumnTransformer\n",
      "\n",
      "Data preparation:\n",
      "Features (X) shape: (1460, 79)\n",
      "Target (y) shape: (1460,)\n",
      "Target statistics: Mean=$180,921, Std=$79,443\n"
     ]
    }
   ],
   "source": [
    "# Load the training data\n",
    "train_df = pd.read_csv('../data/train.csv')\n",
    "test_df = pd.read_csv('../data/test.csv')\n",
    "\n",
    "print(\"Data loaded:\")\n",
    "print(f\"Training data shape: {train_df.shape}\")\n",
    "print(f\"Test data shape: {test_df.shape}\")\n",
    "\n",
    "# Import FeatureEngineer from our custom module\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from feature_engineering import FeatureEngineer\n",
    "\n",
    "print(\"FeatureEngineer imported from module\")\n",
    "\n",
    "# Now load the preprocessing pipeline\n",
    "pipeline_path = Path('../models/preprocessing_pipeline.pkl')\n",
    "preprocessing_pipeline = joblib.load(pipeline_path)\n",
    "\n",
    "print(f\"Preprocessing pipeline loaded successfully!\")\n",
    "print(\"Pipeline steps:\")\n",
    "for i, (name, step) in enumerate(preprocessing_pipeline.steps):\n",
    "    print(f\"  {i+1}. {name}: {type(step).__name__}\")\n",
    "\n",
    "# Prepare features and target\n",
    "X = train_df.drop(['Id', 'SalePrice'], axis=1)\n",
    "y = train_df['SalePrice']\n",
    "\n",
    "print(f\"\\nData preparation:\")\n",
    "print(f\"Features (X) shape: {X.shape}\")\n",
    "print(f\"Target (y) shape: {y.shape}\")\n",
    "print(f\"Target statistics: Mean=${y.mean():,.0f}, Std=${y.std():,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cc2d75-8b78-4056-9419-05db6793d853",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a883561c-2bf2-4541-b15a-ee0316cfd28c",
   "metadata": {},
   "source": [
    "#### Create Complete ML Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c05fd530-47f4-430a-9269-568b0922562f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating complete ML pipelines...\n",
      "Created 5 complete ML pipelines:\n",
      "  - Linear Regression\n",
      "  - Ridge\n",
      "  - Lasso\n",
      "  - Random Forest\n",
      "  - XGBoost\n",
      "\n",
      "Each pipeline includes:\n",
      "  1. Feature engineering (TotalSF, TotalBath, etc.)\n",
      "  2. Preprocessing (imputation, scaling, encoding)\n",
      "  3. Model fitting and prediction\n"
     ]
    }
   ],
   "source": [
    "# Create complete pipelines (preprocessing + model) for different algorithms\n",
    "print(\"Creating complete ML pipelines...\")\n",
    "\n",
    "# 1. Linear Regression Pipeline\n",
    "linear_pipeline = Pipeline([\n",
    "    ('preprocessing', preprocessing_pipeline),\n",
    "    ('model', LinearRegression())\n",
    "])\n",
    "\n",
    "# 2. Ridge Regression Pipeline\n",
    "ridge_pipeline = Pipeline([\n",
    "    ('preprocessing', preprocessing_pipeline),\n",
    "    ('model', Ridge(random_state=42))\n",
    "])\n",
    "\n",
    "# 3. Lasso Regression Pipeline\n",
    "lasso_pipeline = Pipeline([\n",
    "    ('preprocessing', preprocessing_pipeline),\n",
    "    ('model', Lasso(random_state=42))\n",
    "])\n",
    "\n",
    "# 4. Random Forest Pipeline\n",
    "rf_pipeline = Pipeline([\n",
    "    ('preprocessing', preprocessing_pipeline),\n",
    "    ('model', RandomForestRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "# 5. XGBoost Pipeline\n",
    "xgb_pipeline = Pipeline([\n",
    "    ('preprocessing', preprocessing_pipeline),\n",
    "    ('model', xgb.XGBRegressor(random_state=42, verbosity=0))\n",
    "])\n",
    "\n",
    "# Store all pipelines\n",
    "pipelines = {\n",
    "    'Linear Regression': linear_pipeline,\n",
    "    'Ridge': ridge_pipeline,\n",
    "    'Lasso': lasso_pipeline,\n",
    "    'Random Forest': rf_pipeline,\n",
    "    'XGBoost': xgb_pipeline\n",
    "}\n",
    "\n",
    "print(f\"Created {len(pipelines)} complete ML pipelines:\")\n",
    "for name in pipelines.keys():\n",
    "    print(f\"  - {name}\")\n",
    "\n",
    "print(f\"\\nEach pipeline includes:\")\n",
    "print(f\"  1. Feature engineering (TotalSF, TotalBath, etc.)\")\n",
    "print(f\"  2. Preprocessing (imputation, scaling, encoding)\")\n",
    "print(f\"  3. Model fitting and prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716e401f-2f27-47eb-84cd-662af28a3a4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80022595-961a-491a-b06c-8119cf6cb380",
   "metadata": {},
   "source": [
    "#### Train-Test Split and Basic Pipeline Evaluation\n",
    "\n",
    "Split the data and test these pipelines with basic evaluation before we implement GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91b9ef97-3b65-44c2-84d8-d701adf03a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split:\n",
      "Training set: 1168 samples\n",
      "Test set: 292 samples\n",
      "\n",
      "Evaluating pipelines with default parameters...\n",
      "==================================================\n",
      "\n",
      "Training Linear Regression...\n",
      "  Train RMSE: 20,458\n",
      "  Test RMSE: 99,290\n",
      "  Test R²: -0.2853\n",
      "\n",
      "Training Ridge...\n",
      "  Train RMSE: 23,566\n",
      "  Test RMSE: 31,147\n",
      "  Test R²: 0.8735\n",
      "\n",
      "Training Lasso...\n",
      "  Train RMSE: 20,760\n",
      "  Test RMSE: 36,411\n",
      "  Test R²: 0.8272\n",
      "\n",
      "Training Random Forest...\n",
      "  Train RMSE: 11,089\n",
      "  Test RMSE: 28,752\n",
      "  Test R²: 0.8922\n",
      "\n",
      "Training XGBoost...\n",
      "  Train RMSE: 1,232\n",
      "  Test RMSE: 28,479\n",
      "  Test R²: 0.8943\n",
      "\n",
      "Basic evaluation complete!\n"
     ]
    }
   ],
   "source": [
    "# Split the data for evaluation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Data split:\")\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "\n",
    "# Evaluate each pipeline with basic parameters\n",
    "results = {}\n",
    "print(f\"\\nEvaluating pipelines with default parameters...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for name, pipeline in pipelines.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    \n",
    "    # Fit the complete pipeline\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_train_pred = pipeline.predict(X_train)\n",
    "    y_test_pred = pipeline.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "    train_r2 = r2_score(y_train, y_train_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "    \n",
    "    # Store results\n",
    "    results[name] = {\n",
    "        'Train RMSE': train_rmse,\n",
    "        'Test RMSE': test_rmse,\n",
    "        'Train R²': train_r2,\n",
    "        'Test R²': test_r2\n",
    "    }\n",
    "    \n",
    "    print(f\"  Train RMSE: {train_rmse:,.0f}\")\n",
    "    print(f\"  Test RMSE: {test_rmse:,.0f}\")\n",
    "    print(f\"  Test R²: {test_r2:.4f}\")\n",
    "\n",
    "print(f\"\\nBasic evaluation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114204b1-a578-4f6a-8024-f7a1a61c4f43",
   "metadata": {},
   "source": [
    "Performance Analysis\n",
    "\n",
    "    Top Performers:\n",
    "    XGBoost: Test R² = 0.8943 (89.4% variance explained!)\n",
    "    Random Forest: Test R² = 0.8922 (89.2% variance explained)\n",
    "    Ridge: Test R² = 0.8735 (87.4% variance explained)\n",
    "\n",
    "Key Insights:\n",
    "\n",
    "    XGBoost overfitting: Train RMSE = 1,232 vs Test RMSE = 28,479 (needs regularization)\n",
    "    Ridge performing well: Good balance between train/test performance\n",
    "    Linear Regression struggling: Negative R² indicates poor fit\n",
    "    Random Forest: Good performance with reasonable overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902584b1-f152-4b96-83f2-319fa015b8ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bffc164d-80dc-4b20-8acc-c71f6f677841",
   "metadata": {},
   "source": [
    "#### GridSearchCV Setup and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c71b5d5-c515-4d9a-bbae-22ba42af2690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter grids defined:\n",
      "  Ridge: 4 combinations\n",
      "  Lasso: 4 combinations\n",
      "  Random Forest: 18 combinations\n",
      "  XGBoost: 27 combinations\n",
      "\n",
      "Starting GridSearchCV optimization...\n"
     ]
    }
   ],
   "source": [
    "# Define hyperparameter grids for each model\n",
    "param_grids = {\n",
    "    'Ridge': {\n",
    "        'model__alpha': [0.1, 1.0, 10.0, 100.0]\n",
    "    },\n",
    "    'Lasso': {\n",
    "        'model__alpha': [0.001, 0.01, 0.1, 1.0]\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'model__n_estimators': [50, 100, 200],\n",
    "        'model__max_depth': [10, 15, 20],\n",
    "        'model__min_samples_split': [2, 5]\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'model__n_estimators': [50, 100, 200],\n",
    "        'model__max_depth': [3, 6, 9],\n",
    "        'model__learning_rate': [0.01, 0.1, 0.2]\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Hyperparameter grids defined:\")\n",
    "for model_name, params in param_grids.items():\n",
    "    param_combinations = 1\n",
    "    for param_values in params.values():\n",
    "        param_combinations *= len(param_values)\n",
    "    print(f\"  {model_name}: {param_combinations} combinations\")\n",
    "\n",
    "print(f\"\\nStarting GridSearchCV optimization...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e2975f-0599-4e4c-8241-b1b25494463a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "196c0c73-4ec8-414f-a19b-e6abffdb3593",
   "metadata": {},
   "source": [
    "#### Execute GridSearchCV Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "deb6471e-91dd-417d-9b5d-33b7d00bc483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV Optimization Results:\n",
      "==================================================\n",
      "\n",
      "Optimizing Ridge...\n",
      "  Best CV R²: 0.8025\n",
      "  Test R²: 0.8731\n",
      "  Test RMSE: 31,198\n",
      "  Time: 7.0s\n",
      "  Best params: {'model__alpha': 10.0}\n",
      "\n",
      "Optimizing Lasso...\n",
      "  Best CV R²: 0.7365\n",
      "  Test R²: 0.8272\n",
      "  Test RMSE: 36,411\n",
      "  Time: 2.9s\n",
      "  Best params: {'model__alpha': 1.0}\n",
      "\n",
      "Optimizing Random Forest...\n",
      "  Best CV R²: 0.8406\n",
      "  Test R²: 0.8926\n",
      "  Test RMSE: 28,703\n",
      "  Time: 85.9s\n",
      "  Best params: {'model__max_depth': 15, 'model__min_samples_split': 5, 'model__n_estimators': 100}\n",
      "\n",
      "Optimizing XGBoost...\n",
      "  Best CV R²: 0.8603\n",
      "  Test R²: 0.9148\n",
      "  Test RMSE: 25,559\n",
      "  Time: 44.1s\n",
      "  Best params: {'model__learning_rate': 0.1, 'model__max_depth': 3, 'model__n_estimators': 200}\n",
      "\n",
      "GridSearchCV optimization complete!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Store optimized results\n",
    "optimized_results = {}\n",
    "best_models = {}\n",
    "\n",
    "print(\"GridSearchCV Optimization Results:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for model_name in param_grids.keys():\n",
    "    print(f\"\\nOptimizing {model_name}...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Get the pipeline for this model\n",
    "    pipeline = pipelines[model_name]\n",
    "    param_grid = param_grids[model_name]\n",
    "    \n",
    "    # Setup GridSearchCV\n",
    "    grid_search = GridSearchCV(\n",
    "        pipeline,\n",
    "        param_grid,\n",
    "        cv=5,\n",
    "        scoring='r2',\n",
    "        n_jobs=-1,\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    # Fit GridSearchCV\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Get best model\n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_models[model_name] = best_model\n",
    "    \n",
    "    # Make predictions with best model\n",
    "    y_train_pred = best_model.predict(X_train)\n",
    "    y_test_pred = best_model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "    train_r2 = r2_score(y_train, y_train_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "    \n",
    "    # Store results\n",
    "    optimized_results[model_name] = {\n",
    "        'Train RMSE': train_rmse,\n",
    "        'Test RMSE': test_rmse,\n",
    "        'Train R²': train_r2,\n",
    "        'Test R²': test_r2,\n",
    "        'Best Params': grid_search.best_params_,\n",
    "        'CV Score': grid_search.best_score_\n",
    "    }\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"  Best CV R²: {grid_search.best_score_:.4f}\")\n",
    "    print(f\"  Test R²: {test_r2:.4f}\")\n",
    "    print(f\"  Test RMSE: {test_rmse:,.0f}\")\n",
    "    print(f\"  Time: {elapsed_time:.1f}s\")\n",
    "    print(f\"  Best params: {grid_search.best_params_}\")\n",
    "\n",
    "print(f\"\\nGridSearchCV optimization complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0327d3ae-5cd8-41a0-85cd-e8a47b8831ee",
   "metadata": {},
   "source": [
    "Optimization Results Analysis\n",
    "\n",
    "    New Champion: XGBoost\n",
    "    Test R²: 0.9148 (91.5% variance explained!)\n",
    "    Test RMSE: 25,559 (significant improvement from 28,479)\n",
    "    Best params: learning_rate=0.1, max_depth=3, n_estimators=200\n",
    "\n",
    "Performance Improvements:\n",
    "\n",
    "    XGBoost: 0.8943 → 0.9148 (+2.0 percentage points)\n",
    "    Random Forest: 0.8922 → 0.8926 (slight improvement)\n",
    "    Ridge: 0.8735 → 0.8731 (minimal change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71668896-d0dd-457f-9ca3-047e286d498a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e67a05ae-cbe2-4ae4-af8a-82647d011b06",
   "metadata": {},
   "source": [
    "#### Final Model Comparison and Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "060cdd3f-7c82-4aa7-857d-945a0465780b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL MODEL COMPARISON\n",
      "============================================================\n",
      "Model           Basic R²   Optimized R² Improvement  RMSE      \n",
      "------------------------------------------------------------\n",
      "XGBoost         0.8943     0.9148       0.0206       25,559    \n",
      "Random Forest   0.8922     0.8926       0.0004       28,703    \n",
      "Ridge           0.8735     0.8731       -0.0004      31,198    \n",
      "Lasso           0.8272     0.8272       0.0000       36,411    \n",
      "\n",
      "CHAMPION MODEL: XGBoost\n",
      "Final Performance: R² = 0.9148, RMSE = $25,559\n",
      "Best Parameters: {'model__learning_rate': 0.1, 'model__max_depth': 3, 'model__n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "# Create comprehensive comparison\n",
    "print(\"FINAL MODEL COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Combine basic and optimized results for comparison\n",
    "comparison_data = []\n",
    "for model_name in ['Ridge', 'Lasso', 'Random Forest', 'XGBoost']:\n",
    "    if model_name in results:\n",
    "        basic_r2 = results[model_name]['Test R²']\n",
    "        basic_rmse = results[model_name]['Test RMSE']\n",
    "    else:\n",
    "        basic_r2 = basic_rmse = 0\n",
    "    \n",
    "    if model_name in optimized_results:\n",
    "        opt_r2 = optimized_results[model_name]['Test R²']\n",
    "        opt_rmse = optimized_results[model_name]['Test RMSE']\n",
    "        improvement = opt_r2 - basic_r2\n",
    "    else:\n",
    "        opt_r2 = opt_rmse = improvement = 0\n",
    "    \n",
    "    comparison_data.append({\n",
    "        'Model': model_name,\n",
    "        'Basic R²': basic_r2,\n",
    "        'Optimized R²': opt_r2,\n",
    "        'Improvement': improvement,\n",
    "        'Final RMSE': opt_rmse\n",
    "    })\n",
    "\n",
    "# Sort by optimized R²\n",
    "comparison_data.sort(key=lambda x: x['Optimized R²'], reverse=True)\n",
    "\n",
    "print(f\"{'Model':<15} {'Basic R²':<10} {'Optimized R²':<12} {'Improvement':<12} {'RMSE':<10}\")\n",
    "print(\"-\" * 60)\n",
    "for data in comparison_data:\n",
    "    print(f\"{data['Model']:<15} {data['Basic R²']:<10.4f} {data['Optimized R²']:<12.4f} \"\n",
    "          f\"{data['Improvement']:<12.4f} {data['Final RMSE']:<10,.0f}\")\n",
    "\n",
    "# Identify the champion\n",
    "champion = comparison_data[0]\n",
    "print(f\"\\nCHAMPION MODEL: {champion['Model']}\")\n",
    "print(f\"Final Performance: R² = {champion['Optimized R²']:.4f}, RMSE = ${champion['Final RMSE']:,.0f}\")\n",
    "\n",
    "# Show best hyperparameters for champion\n",
    "if champion['Model'] in optimized_results:\n",
    "    print(f\"Best Parameters: {optimized_results[champion['Model']]['Best Params']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab735b6d-f5d5-4313-8334-ac20cb1408f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "31cccf9e-2fa8-45ee-a344-acb141054b78",
   "metadata": {},
   "source": [
    "#### Save Champion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9341890d-26d4-45e0-ade1-2038a49dba6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING CHAMPION MODEL FOR PRODUCTION\n",
      "========================================\n",
      "Champion model saved: ..\\models\\champion_xgboost_model.pkl\n",
      "Model: XGBoost\n",
      "Performance: R² = 0.9148\n",
      "RMSE: $25,559\n",
      "Best Parameters: {'model__learning_rate': 0.1, 'model__max_depth': 3, 'model__n_estimators': 200}\n",
      "\n",
      "Model verification: Successfully loaded from disk\n",
      "Model type: <class 'sklearn.pipeline.Pipeline'>\n",
      "\n",
      "Ready for production deployment!\n"
     ]
    }
   ],
   "source": [
    "# Save the champion model for production deployment\n",
    "print(\"SAVING CHAMPION MODEL FOR PRODUCTION\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Get the champion model (XGBoost from our results)\n",
    "champion_model = best_models['XGBoost']\n",
    "champion_name = 'XGBoost'\n",
    "\n",
    "# Create models directory path\n",
    "models_dir = Path('../models')\n",
    "models_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Save the complete champion pipeline\n",
    "champion_model_path = models_dir / 'champion_xgboost_model.pkl'\n",
    "joblib.dump(champion_model, champion_model_path)\n",
    "\n",
    "print(f\"Champion model saved: {champion_model_path}\")\n",
    "print(f\"Model: {champion_name}\")\n",
    "print(f\"Performance: R² = {optimized_results[champion_name]['Test R²']:.4f}\")\n",
    "print(f\"RMSE: ${optimized_results[champion_name]['Test RMSE']:,.0f}\")\n",
    "print(f\"Best Parameters: {optimized_results[champion_name]['Best Params']}\")\n",
    "\n",
    "# Verify the saved model can be loaded\n",
    "try:\n",
    "    loaded_model = joblib.load(champion_model_path)\n",
    "    print(f\"\\nModel verification: Successfully loaded from disk\")\n",
    "    print(f\"Model type: {type(loaded_model)}\")\n",
    "    print(f\"\\nReady for production deployment!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3acd46-719b-4f6a-bf80-d82a791e405e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
